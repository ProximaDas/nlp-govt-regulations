{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code extracts documents and related comments from documents in different categories. There are 10 categories in regulation.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "import pandas\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "api_key = 'vT4R3vZ8RpZhnCpgeCPx1LdWRSZS8yxHHGquPrxm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file_get_docid(filepath):\n",
    "    dump_df = load(open(filepath,'rb'))\n",
    "    df_with_comments = dump_df[dump_df.numberOfCommentsReceived > 0]\n",
    "    doc_id = df_with_comments.documentId\n",
    "    doc_type = df_with_comments.documentType\n",
    "    return [doc_id,set(doc_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rule', 'Notice', 'Proposed Rule', 'Other'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "761"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc_id_list,types] = read_file_get_docid('data/BFS_doc_list') #choose the category dump file\n",
    "print(types)\n",
    "# document ID with 4 parts represent documents. 3 parts represent dockets \n",
    "doc_ids = [doc_id for doc_id in doc_id_list if len(doc_id.split('-')) == 4]\n",
    "len(doc_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regulations.gov API\n",
    "* We need to use the API to retrieve each document content. This API will use document_id that we extracted from the file above.\n",
    "* For each document_id, we will need to construct comment_id based on the total number of comments on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_file(download_url):\n",
    "    response = urllib.request.urlopen(download_url)\n",
    "    file = open(\"document.pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()\n",
    "    \n",
    "def get_attached_comments(comment_id, key=api_key):\n",
    "    #print(each_id) # fro debugging\n",
    "    #open the api to get file url\n",
    "    url = \"http://api.data.gov:80/regulations/v3/document.json?api_key=\"+key+\"&documentId=\"+comment_id\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code)\n",
    "    data = response.json()\n",
    "    link = data[\"attachments\"][0][\"fileFormats\"][0] # assuming there is only 1 attachment and extracting the pdf link\n",
    "    access_link = link+'&api_key='+key\n",
    "    #download file(pdf) and read pdf (page by page)\n",
    "    download_file(access_link)\n",
    "    pdfFileObj = open('document.pdf','rb')     #'rb' for read binary mode\n",
    "    comment_text =\"\"\n",
    "    try:\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        pno = pdfReader.numPages\n",
    "        for i in range(pno):\n",
    "            pageObj = pdfReader.getPage(i)          #'i' is the page number\n",
    "            comment_text += pageObj.extractText()\n",
    "    except:\n",
    "        print(\"cant read \"+comment_id) # prints in case we are not able to read file\n",
    "    return comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_document_comments_from_api(docketId,key=api_key):\n",
    "    offset=0\n",
    "    url = \"http://api.data.gov:80/regulations/v3/documents.json?api_key=\"+key+\"&countsOnly=1&dct=PS&dktid=\"+docketId\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code)\n",
    "    data = response.json()\n",
    "    total = data['totalNumRecords']\n",
    "    com_list =[]\n",
    "    for i in range(0,total,500):\n",
    "        url = \"http://api.data.gov:80/regulations/v3/documents.json?api_key=\"+key+\"&countsOnly=0&&rpp=500&po=\"+str(i)+\"&dktid=\"+docketId\n",
    "        response = requests.get(url)\n",
    "        #print(\"Offset:\"+str(i)+\" Code:\"+str(response.status_code))\n",
    "        data = response.json()\n",
    "        com_list += data['documents']\n",
    "    com_df = pandas.DataFrame(com_list)\n",
    "    return com_df\n",
    "\n",
    "def get_document_content_from_api(docId,key=api_key):\n",
    "    url = \"http://api.data.gov:80/regulations/v3/document.json?api_key=\"+key+\"&documentId=\"+docId\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Get HTML for document content\n",
    "    link = data['fileFormats'][1] # The second link is the document in HTML format\n",
    "    access_link = link+'&api_key='+key\n",
    "    \n",
    "    with urllib.request.urlopen(access_link) as response:\n",
    "        html = response.read()\n",
    "    \n",
    "    # We are interested in the pre tag of the HTML content\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    content = soup.find_all('pre')\n",
    "    \n",
    "    # Now we need to construct comment_id from document_id\n",
    "    docket_id = '-'.join(docId.split('-')[:3])\n",
    "    comment_df = get_document_comments_from_api(docket_id)\n",
    "    # get comment text where exists\n",
    "    if df.empty:\n",
    "        comment_list =[]\n",
    "    else:\n",
    "        comment_text =comment_df[comment_df.commentText.notnull()].commentText\n",
    "        comment_list =comment_text.tolist()\n",
    "        #get doc id where there is attchment\n",
    "        c_ids = comment_df[comment_df.attachmentCount>0].documentId\n",
    "        # get comment for each id in list\n",
    "        for each_id in c_ids.unique():\n",
    "            comment_list.append(get_attached_comments(each_id))\n",
    "    doc_dict = {\n",
    "        \"text\":content,\n",
    "        \"comment_list\":comment_list\n",
    "    }\n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running it on one document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling APIs for  ASC-2016-0004-0001\n",
      "cant read ASC-2016-0004-0011\n",
      "cant read ASC-2016-0004-0046\n",
      "Calling APIs for  CDFI-2013-0001-0001\n",
      "cant read CDFI-2013-0001-0009\n",
      "cant read CDFI-2013-0001-0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n",
      "PdfReadWarning: Invalid stream (index 1) within object 9 0: Stream has ended unexpectedly [pdf.py:1573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cant read CDFI-2013-0001-0030\n",
      "cant read CDFI-2013-0001-0035\n",
      "cant read CDFI-2013-0001-0002\n",
      "cant read CDFI-2013-0001-0008\n",
      "Calling APIs for  CDFI-2016-0001-0001\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'commentText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-417bb2897d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling APIs for '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_document_content_from_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdoc_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7e4fb98493e6>\u001b[0m in \u001b[0;36mget_document_content_from_api\u001b[0;34m(docId, key)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcomment_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_document_comments_from_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# get comment text where exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mcomment_text\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcomment_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomment_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommentText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommentText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mcomment_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcomment_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#get doc id where there is attchment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Proxima/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'commentText'"
     ]
    }
   ],
   "source": [
    "doc_collection = []\n",
    "for i in range(10):\n",
    "    print('Calling APIs for ',doc_ids[i])\n",
    "    resp = get_document_content_from_api(doc_ids[i])\n",
    "    doc_collection.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### next steps\n",
    "1. Run it on say top ten document id (based on number of attachment in desc order) for each category\n",
    "2. Each doc output from the get_document_content_from_api file will be a dictionary, create a data frame from all the document and comments you extract (say a data frame of 10 row)\n",
    "3. dump the data frame in a file like\n",
    "\n",
    "```output = open('LES_doc_content', 'wb')\n",
    "dump(df, output, -1)\n",
    "output.close()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection_df = pandas.DataFrame(doc_collection)\n",
    "output = open('BFS_doc_content', 'wb')\n",
    "dump(collection_df, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = get_document_comments_from_api('CDFI-2016-0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
